import streamlit as st
import pandas as pd
import re
import requests
from bs4 import BeautifulSoup
from transformers import BertTokenizerFast, BertForTokenClassification, pipeline
import torch

# ==========================================
# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (ìºì‹± ì ìš©)
# ==========================================
st.set_page_config(page_title="Aero-Post Generator", page_icon="âœˆï¸", layout="wide")

@st.cache_resource
def load_resources():
    # 1. ëª¨ë¸ ë¡œë“œ
    model_path = "./model"  # ë¡œì»¬ í´ë” ê²½ë¡œ
    try:
        model = BertForTokenClassification.from_pretrained(model_path)
        tokenizer = BertTokenizerFast.from_pretrained(model_path)
        
        # ë¼ë²¨ ì •ë³´ ìˆ˜ë™ ì£¼ì… (config.jsonì— ì €ì¥ ì•ˆ ëì„ ê²½ìš° ëŒ€ë¹„)
        id2label = {0: 'B-AIRCRAFT', 1: 'B-AIRLINE', 2: 'B-DATE', 3: 'I-ROUTE', 4: 'O'}
        label2id = {v: k for k, v in id2label.items()}
        model.config.id2label = id2label
        model.config.label2id = label2id
        
        nlp = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, {}, {}, {}, {}, {}, {}

    # 2. ë°ì´í„° ë¡œë“œ
    try:
        df_airport = pd.read_csv('data/airports_list.csv', encoding='cp949').dropna(subset=['ê³µí•­ì½”ë“œ1(IATA)', 'í•œê¸€ê³µí•­'])
        df_airline = pd.read_csv('data/airlines_list.csv', encoding='cp949').dropna(subset=['í•­ê³µì‚¬ì½”ë“œ_IATA', 'í•œê¸€í•­ê³µì‚¬ëª…'])
        
        # ê¸°ì¢… ë°ì´í„° ë¡œë“œ (ì¸ì½”ë”© ìë™ ê°ì§€ ì‹œë„)
        try:
            df_aircraft = pd.read_csv('data/aircrafts_list.csv', encoding='utf-8')
        except:
            df_aircraft = pd.read_csv('data/aircrafts_list.csv', encoding='cp949')

        # ì‚¬ì „ êµ¬ì¶•
        airport_dict = dict(zip(df_airport['ê³µí•­ì½”ë“œ1(IATA)'], df_airport['í•œê¸€ê³µí•­']))
        airline_dict = dict(zip(df_airline['í•­ê³µì‚¬ì½”ë“œ_IATA'], df_airline['í•œê¸€í•­ê³µì‚¬ëª…']))
        
        name_to_kor_airline = dict(zip(df_airline['ì˜ë¬¸í•­ê³µì‚¬ëª…'], df_airline['í•œê¸€í•­ê³µì‚¬ëª…']))
        name_to_kor_airport = dict(zip(df_airport['ì˜ë¬¸ê³µí•­ëª…'], df_airport['í•œê¸€ê³µí•­']))
        name_to_kor_airport.update(dict(zip(df_airport['ì˜ë¬¸ë„ì‹œëª…'], df_airport['í•œê¸€ê³µí•­'])))
        
        # ê¸°ì¢… ì‚¬ì „ (IATA -> FullName)
        aircraft_dict = {}
        for _, row in df_aircraft.iterrows():
            code = str(row['í•­ê³µê¸°ì½”ë“œ_IATA']).strip()
            if code and code != 'nan':
                aircraft_dict[code] = (str(row['ì œì¡°ì‚¬']).title(), str(row['ë¹„í–‰ê¸°ëª¨ë¸']))

        # ìˆ˜ë™ ë³´ì •
        manual_fixes = {
            'MAD': 'ë§ˆë“œë¦¬ë“œ ë°”ë¼í•˜ìŠ¤ êµ­ì œê³µí•­', 'DOH': 'ë„í•˜ í•˜ë§ˆë“œ êµ­ì œê³µí•­',
            'TUN': 'íŠ€ë‹ˆìŠ¤ ì¹´ë¥´íƒ€ê³  ê³µí•­', 'BER': 'ë² ë¥¼ë¦° ë¸Œë€ë´ë¶€ë¥´í¬ ê³µí•­',
            'ICN': 'ì¸ì²œêµ­ì œê³µí•­', 'NRT': 'ë„ì¿„ ë‚˜ë¦¬íƒ€ ê³µí•­',
            'HKG': 'í™ì½© ì²µëì½• êµ­ì œê³µí•­', 'SFO': 'ìƒŒí”„ë€ì‹œìŠ¤ì½” êµ­ì œê³µí•­',
            'KUL': 'ì¿ ì•Œë¼ë£¸í‘¸ë¥´ êµ­ì œê³µí•­', 'CGK': 'ìì¹´ë¥´íƒ€ ìˆ˜ì¹´ë¥´ë…¸ í•˜íƒ€ êµ­ì œê³µí•­',
            'HAN': 'í•˜ë…¸ì´ ë…¸ì´ë°”ì´ êµ­ì œê³µí•­', 'DAD': 'ë‹¤ë‚­ êµ­ì œê³µí•­',
            'OOL': 'ê³¨ë“œì½”ìŠ¤íŠ¸(ì¿¨ë‘ê°€íƒ€) ê³µí•­',
            'Air Europa': 'ì—ì–´ ìœ ë¡œíŒŒ', 'Eurowings': 'ìœ ë¡œìœ™ìŠ¤',
            'Hong Kong Airlines': 'í™ì½©í•­ê³µ', 'Asiana Airlines': 'ì•„ì‹œì•„ë‚˜í•­ê³µ'
        }
        airport_dict.update(manual_fixes)
        airline_dict.update(manual_fixes)
        name_to_kor_airline.update(manual_fixes)

        # ê²€ìƒ‰ìš© ë¦¬ìŠ¤íŠ¸
        sorted_airline_names = sorted(name_to_kor_airline.keys(), key=len, reverse=True)
        sorted_airport_names = sorted(name_to_kor_airport.keys(), key=len, reverse=True)
        
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return nlp, {}, {}, {}, {}, {}, {}

    return nlp, airport_dict, airline_dict, name_to_kor_airline, name_to_kor_airport, sorted_airline_names, sorted_airport_names, aircraft_dict

# ë¦¬ì†ŒìŠ¤ ë¡œë“œ
nlp, airport_dict, airline_dict, name_to_kor_airline, name_to_kor_airport, sorted_airline_names, sorted_airport_names, aircraft_dict = load_resources()

# ==========================================
# 2. í—¬í¼ í•¨ìˆ˜ë“¤ (Logic)
# ==========================================
def clean_garbage_words(text):
    if not text: return ""
    text = re.sub(r'(route|service|airport|flights?|eff)$', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\b(route|service|airport|flights?|eff)\b', '', text, flags=re.IGNORECASE)
    return re.sub(r'\s+', ' ', text).strip()

def clean_location_name(name):
    if not name: return ""
    name = clean_garbage_words(name)
    name = re.sub(r'\s*\([^)]*\)$', '', name).strip()
    return name

def normalize_aircraft_name(name):
    if not name: return ""
    name = name.upper().replace("BOEING", "B").replace("AIRBUS", "A").strip()
    if re.match(r'^7\d{2}', name): name = "B" + name
    name = name.replace("B B", "B").replace("A A", "A")
    return name

def get_aircraft_fullname(code):
    if not code: return ""
    c = code.upper().replace("BOEING", "").replace("AIRBUS", "").replace(" ", "").replace("-", "")
    if c.startswith("B7"): c = c[1:]
    candidates = [c, "A"+c, "B"+c, c.replace("A", ""), c.replace("B", "")]
    for cand in candidates:
        if cand in aircraft_dict:
            maker, model = aircraft_dict[cand]
            maker_kr = "ë³´ì‰" if "BOEING" in maker.upper() else "ì—ì–´ë²„ìŠ¤" if "AIRBUS" in maker.upper() else maker
            return f"{maker_kr} {model}"
    if "777" in code: return "ë³´ì‰ 777"
    if "787" in code: return "ë³´ì‰ 787"
    if "350" in code: return "ì—ì–´ë²„ìŠ¤ A350"
    if "330" in code: return "ì—ì–´ë²„ìŠ¤ A330"
    if "320" in code or "321" in code: return "ì—ì–´ë²„ìŠ¤ A320 ê³„ì—´"
    return code

def format_date(raw_date):
    try:
        months = {'JAN':1, 'FEB':2, 'MAR':3, 'APR':4, 'MAY':5, 'JUN':6, 'JUL':7, 'AUG':8, 'SEP':9, 'OCT':10, 'NOV':11, 'DEC':12}
        match = re.match(r'(\d{1,2})([A-Z]{3})(\d{2})', raw_date)
        if match:
            day, m_str, _ = match.groups()
            return f"{months.get(m_str.upper())}ì›” {day}ì¼"
    except: pass
    return ""

def format_time_pretty(time_str):
    match = re.match(r'(\d{2})(\d{2})([+]?\d*)', time_str)
    if match:
        hh, mm, plus = match.groups()
        time_fmt = f"{hh}:{mm}"
        if plus: time_fmt += f"({plus})"
        return time_fmt
    return time_str

def get_korean_smart(text, raw_text, type='airline'):
    text = clean_garbage_words(text)
    if type == 'airline' and text in airline_dict: return airline_dict[text]
    if type == 'airport' and text in airport_dict: return airport_dict[text]
    if type == 'airline' and text in name_to_kor_airline: return name_to_kor_airline[text]
    
    search_list = sorted_airline_names if type == 'airline' else sorted_airport_names
    target_dict = name_to_kor_airline if type == 'airline' else name_to_kor_airport
    
    found_candidate = None
    for name in search_list:
        if not name: continue
        if name in raw_text:
            kor_name = target_dict.get(name)
            if not kor_name: continue
            if type == 'airport':
                if 'êµ­ì œê³µí•­' in kor_name or 'International' in name: return kor_name
                if not found_candidate: found_candidate = kor_name
            else: return kor_name
    
    if len(text) > 2:
        for eng_name, kor_name in target_dict.items():
            if not eng_name: continue
            if text.lower() in str(eng_name).lower():
                if type == 'airport':
                    if 'êµ­ì œê³µí•­' in kor_name or 'International' in eng_name: return kor_name
                else: return kor_name
    if found_candidate: return found_candidate
    return text

def extract_frequency_and_days(text):
    if not text: return None, None
    t = text.lower()
    weekday_map = {"1": "ì›”", "2": "í™”", "3": "ìˆ˜", "4": "ëª©", "5": "ê¸ˆ", "6": "í† ", "7": "ì¼"}
    frequency, days_list = None, None
    weekly_patterns = [r'(\d+)\s*weekly', r'operates\s+(\d+)\s*weekly', r'(\d+)\s+times\s+weekly', r'(\d+)\s*Ã—\s*weekly']
    for pat in weekly_patterns:
        m = re.search(pat, t)
        if m:
            try:
                val = int(m.group(1))
                if 1 <= val <= 30: frequency = str(val); break
            except: continue
    x_matches = re.findall(r'x([1-7]{1,7})', t)
    if x_matches:
        digits = x_matches[0]
        seen = set()
        days = []
        for d in digits:
            if d in weekday_map and d not in seen: seen.add(d); days.append(weekday_map[d])
        if days:
            days_list = days
            if frequency is None: frequency = str(len(days))
    return frequency, days_list

def extract_network_routes(text):
    routes = []
    lines = text.splitlines()
    pattern = re.compile(r"^\s*(?P<start>.+?)\s+[â€“-]\s+(?P<end>.+?)\s+eff\s+(?P<eff>\d{2}[A-Z]{3}\d{2})\s+(?P<count>\d+)\s+(?P<unit>weekly|daily)(?:\s+(?P<ac>.+?))?(?:\s*\(.*)?$", re.IGNORECASE)
    for line in lines:
        m = pattern.match(line.strip())
        if not m: continue
        start_en = clean_location_name(m.group("start"))
        end_en = clean_location_name(m.group("end"))
        start_en = re.sub(r'\s[A-Z]{2}$', '', start_en)
        end_en = re.sub(r'\s[A-Z]{2}$', '', end_en)
        routes.append({
            "start_en": start_en, "end_en": end_en, "eff_date": m.group("eff"),
            "count": m.group("count"), "unit": m.group("unit").lower(), "aircraft": (m.group("ac") or "").strip()
        })
    return routes

def classify_action_from_title(title, text, is_codeshare, aircraft_str):
    t = (title + " " + text[:200]).lower()
    if is_codeshare or "codeshare" in t: return "ì½”ë“œì‰ì–´", "ë…¸ì„ ì˜ ê³µë™ìš´í•­ í˜‘ì•½ì„ ë§ºì—ˆìŠµë‹ˆë‹¤."
    if any(k in t for k in ["launches", "launch", "inaugural", "new route", "plans", "opens new"]): return "ì‹ ê·œ ì·¨í•­", "í•´ë‹¹ ë…¸ì„ ì„ ì‹ ê·œ ì·¨í•­í•©ë‹ˆë‹¤."
    if any(k in t for k in ["resumes", "resume", "restores", "reinstates", "relaunches"]): return "ìš´í•­ ì¬ê°œ", "ì¤‘ë‹¨ë˜ì—ˆë˜ ë…¸ì„  ìš´í•­ì„ ì¬ê°œí•©ë‹ˆë‹¤."
    if any(k in t for k in ["extra", "increase", "increases", "boosts"]): return "ì¦í¸", "ë…¸ì„  ìš´í•­ì„ ì¦í¸í•©ë‹ˆë‹¤."
    if any(k in t for k in ["reduces", "reduce", "suspends", "suspension"]): return "ê°í¸/ë‹¨ì¶•", "ë…¸ì„  ìš´í•­ì„ ê°í¸í•©ë‹ˆë‹¤."
    aircraft_str = (aircraft_str or "").strip()
    if aircraft_str: return f"{aircraft_str} íˆ¬ì…", f"ë…¸ì„ ì— {aircraft_str} ê¸°ì¬ë¥¼ íˆ¬ì…(ë˜ëŠ” ì¦í¸)í•©ë‹ˆë‹¤."
    else: return "ë…¸ì„  ë³€ê²½", "ë…¸ì„  ìŠ¤ì¼€ì¤„ì„ ë³€ê²½í•©ë‹ˆë‹¤."

def generate_caption(title, text, link):
    raw_text = text
    if "Published at" in text: text = text.split("Published at")[-1]
    text = re.sub(r'^.*GMT \d{2}[A-Z]{3}\d{2}', '', text).strip()
    
    results = nlp(text)
    info = {"AIRLINE": [], "AIRCRAFT": "", "DATE": "", "ROUTE_START": "", "ROUTE_END": ""}
    for entity in results:
        label, word = entity['entity_group'], entity['word'].replace(" ##", "").replace("##", "")
        if "AIRLINE" in label and word not in info['AIRLINE']: info['AIRLINE'].append(word)
        elif "AIRCRAFT" in label and not info['AIRCRAFT']: info['AIRCRAFT'] = word
        elif "DATE" in label and not info['DATE']: info['DATE'] = word
        
    is_codeshare = False
    if "codeshare" in text.lower() or "partner" in text.lower(): is_codeshare = True
    if "/" in text and re.search(r'[A-Z0-9]{2,3}\d{3,4}\/[A-Z0-9]{2,3}\d{3,4}', text): is_codeshare = True

    ac_match = re.search(r'(A3\d{2}(-\d{3,4})?|7\d{2}(-\d{3,4})?|Boeing\s7\d{2}|Airbus\sA3\d{2}|A220-300)', text)
    if ac_match: info['AIRCRAFT'] = normalize_aircraft_name(ac_match.group(0))
    else: info['AIRCRAFT'] = normalize_aircraft_name(info['AIRCRAFT'])
    
    date_match = re.search(r'\d{1,2}[A-Z]{3}\d{2}', text)
    if date_match: info['DATE'] = date_match.group(0)
    
    route_match = re.search(r'([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)\s?[â€“-]\s?([A-Z][a-z]+(?:\s[A-Z][a-z]+)*)', text)
    if route_match:
        info['ROUTE_START'] = clean_location_name(route_match.group(1))
        info['ROUTE_END'] = clean_location_name(route_match.group(2))

    schedule_pattern = r'([A-Z0-9]{2,3}\d{3,4}(?:/[A-Z0-9]{2,3}\d{3,4})?)\s+([A-Z]{3})(\d{3,4}[+]?\d*)\s*[â€“-]\s*(\d{3,4}(?:[+]?\d*)?)\s*([A-Z]{3})'
    schedules = re.findall(schedule_pattern, text)
    network_routes = extract_network_routes(text)
    frequency, days_list = extract_frequency_and_days(text)

    potential_airlines = info['AIRLINE'][:]
    for eng_name, kor_name in name_to_kor_airline.items():
        if eng_name in title and eng_name not in potential_airlines: potential_airlines.append(eng_name)
    
    seen, airlines_kr = set(), []
    for al in potential_airlines:
        kr = get_korean_smart(al, raw_text, 'airline')
        if kr not in seen and kr != al: seen.add(kr); airlines_kr.append(kr)
    if not airlines_kr: airlines_kr = ["í•´ë‹¹ í•­ê³µì‚¬"]
    airline_text = "-".join(airlines_kr[:2])

    if schedules:
        _, dep_code, _, _, arr_code = schedules[0]
        start_kr = airport_dict.get(dep_code, info['ROUTE_START'] or "ì¶œë°œì§€")
        end_kr = airport_dict.get(arr_code, info['ROUTE_END'] or "ë„ì°©ì§€")
    elif network_routes:
        start_kr = get_korean_smart(network_routes[0]['start_en'], raw_text, 'airport')
        end_kr = get_korean_smart(network_routes[0]['end_en'], raw_text, 'airport')
    else:
        start_kr = get_korean_smart(info['ROUTE_START'], raw_text, 'airport') if info['ROUTE_START'] else "ì¶œë°œì§€"
        end_kr = get_korean_smart(info['ROUTE_END'], raw_text, 'airport') if info['ROUTE_END'] else "ë„ì°©ì§€"

    date_kr = format_date(info['DATE'])
    title_suffix, body_msg = classify_action_from_title(title, text, is_codeshare, info['AIRCRAFT'])

    caption = []
    month_text = f"{date_kr.split('ì›”')[0]}ì›”" if date_kr and "ì›”" in date_kr else ""
    headline = f"âœˆï¸ [ë‰´ìŠ¤] {airline_text}, {month_text}ë¶€í„° {end_kr} {title_suffix}" if month_text else f"âœˆï¸ [ë‰´ìŠ¤] {airline_text}, {end_kr} {title_suffix}"
    caption.append(headline + "\n")
    
    start_msg = f"ì˜¤ëŠ” {date_kr}ë¶€í„°" if date_kr else ""
    caption.append(f"ğŸ“¢ {airline_text}ì´(ê°€) {start_msg} {start_kr} - {end_kr} {body_msg}")
    
    ac_full = get_aircraft_fullname(info['AIRCRAFT'])
    if ac_full and not is_codeshare:
        caption.append(f"ğŸ’º í•´ë‹¹ ë…¸ì„ ì—ëŠ” {ac_full}ì´(ê°€) íˆ¬ì…ë  ì˜ˆì •ì…ë‹ˆë‹¤.")

    if schedules:
        freq_line = f"í•´ë‹¹ ìš´í•­í¸ì€ ì£¼ {frequency}íšŒ í¸ì„±ë˜ë©° ({', '.join(days_list)})" if frequency and days_list and int(frequency) == len(days_list) else f"í•´ë‹¹ ìš´í•­í¸ì€ ì£¼ {frequency}íšŒ í¸ì„±ë˜ë©°" if frequency else "ìƒì„¸ ìŠ¤ì¼€ì¤„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤"
        caption.append(f"\nğŸ—“ï¸ {freq_line}, ìƒì„¸ ìŠ¤ì¼€ì¤„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n")
        for s in schedules:
            flt, dep_code, dep_tm, arr_tm, arr_code = s 
            if len(flt) >= 5 and flt[0].isdigit(): flt = flt[1:]
            dep_nm = airport_dict.get(dep_code, dep_code)
            arr_nm = airport_dict.get(arr_code, arr_code)
            caption.append(f"  * {flt}: {dep_nm}({dep_code}) {format_time_pretty(dep_tm)} ì¶œë°œ â” {arr_nm}({arr_code}) {format_time_pretty(arr_tm)} ë„ì°©")
    elif network_routes:
        caption.append("\nğŸ—“ï¸ ì‹ ê·œ ë…¸ì„  ìƒì„¸:\n")
        for r in network_routes:
            eff_kr = format_date(r['eff_date'])
            s_net = get_korean_smart(r['start_en'], raw_text, 'airport')
            e_net = get_korean_smart(r['end_en'], raw_text, 'airport')
            freq_str = f"ì£¼ {r['count']}íšŒ" if r["unit"]=="weekly" else f"í•˜ë£¨ {r['count']}íšŒ"
            line = f"  * {s_net} â€“ {e_net}: {eff_kr}ë¶€í„° {freq_str} ìš´í•­"
            if r['aircraft']: line += f" ({r['aircraft']})"
            caption.append(line)
    else:
        caption.append("\nğŸ—“ï¸ ìƒì„¸ ìš´í•­ ìŠ¤ì¼€ì¤„ì€ í•­ê³µì‚¬ í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.")
        
    caption.append(f"\nğŸ”— ì¶œì²˜: [AeroRoutes] {link}")
    caption.append("ğŸ“¸")
    return "\n".join(caption)

# ==========================================
# 3. UI êµ¬ì„±
# ==========================================
st.title("âœˆï¸ Aero-Post Generator")
st.markdown("í•­ê³µ ë‰´ìŠ¤ ìº¡ì…˜ ìë™ ìƒì„±ê¸° (Instagram Format)")

if not nlp:
    st.error("ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data í´ë”ì™€ model í´ë”ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
else:
    tab1, tab2 = st.tabs(["ğŸ”— ë§í¬ë¡œ ìƒì„±", "ğŸ“ í…ìŠ¤íŠ¸ë¡œ ìƒì„±"])

    with tab1:
        url_input = st.text_input("AeroRoutes ê¸°ì‚¬ URL")
        if st.button("ìº¡ì…˜ ìƒì„± (Link)"):
            if url_input:
                with st.spinner('í¬ë¡¤ë§ ì¤‘...'):
                    try:
                        headers = {'User-Agent': 'Mozilla/5.0'}
                        res = requests.get(url_input, headers=headers)
                        soup = BeautifulSoup(res.text, 'html.parser')
                        title_tag = soup.find('h1', class_='blog-title')
                        if not title_tag: title_tag = soup.find('h1', class_='entry-title')
                        title = title_tag.get_text(strip=True) if title_tag else "ì œëª© ì—†ìŒ"
                        
                        content = ""
                        for cls in ['entry-content', 'sqs-block-content', 'BlogList-item-excerpt']:
                            div = soup.find('div', class_=cls)
                            if div: content = div.get_text("\n", strip=True); break
                        
                        if content:
                            result = generate_caption(title, content, url_input)
                            st.success("ìƒì„± ì™„ë£Œ!")
                            st.text_area("ê²°ê³¼ (ë³µì‚¬í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”)", value=result, height=400)
                        else:
                            st.error("ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
    
    with tab2:
        title_in = st.text_input("ì œëª© (ì„ íƒì‚¬í•­)", value="í•­ê³µ ë‰´ìŠ¤")
        text_in = st.text_area("ê¸°ì‚¬ ë³¸ë¬¸", height=200)
        if st.button("ìº¡ì…˜ ìƒì„± (Text)"):
            if text_in:
                with st.spinner('ë¶„ì„ ì¤‘...'):
                    result = generate_caption(title_in, text_in, "https://www.aeroroutes.com")
                    st.success("ìƒì„± ì™„ë£Œ!")
                    st.text_area("ê²°ê³¼", value=result, height=400)